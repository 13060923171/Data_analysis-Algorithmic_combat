# 什么是SVM

说白了SVM就是一个分类器，红球和篮球就是我们的类别，而SVM就是这条黑色的线，把这些物体给划分出来

![image-20210806150652619](https://gitee.com/mqsnq30/gitee-table/raw/master/img/20210806150652.png)

## SVM的工作原理

SVM有一个特有的概念：分类间隔

在保证决策面不变，且分类不产生错误的情况下，我们可以移动决策面C，直到产生两个极限的位置：如图中的决策面A和决策面B。极限的位置是指，如果越过了这个位置，就会生产分类错误。这样的话，两个极限位置A和B直接的分界线C就是最优决策面。极限位置到最优决策面C之间的距离就是“分类间隔”，英文叫margin。

如果我们转动这个最优决策面，你会发现可能存在多个最优决策面，它们都能把数据集正确分开，这些最优决策面的分类间隔可能是不同的，而那个拥有“最大间隔”（max margin）的决策面就是SVM要找的最优解。

![image-20210806151255326](https://gitee.com/mqsnq30/gitee-table/raw/master/img/20210806151255.png)

## 点到超平面的距离公式

![image-20210806151326847](https://gitee.com/mqsnq30/gitee-table/raw/master/img/20210806151326.png)

![image-20210806151350255](https://gitee.com/mqsnq30/gitee-table/raw/master/img/20210806151350.png)

## SVM有最大间隔的优化模型和硬间隔，软间隔，非线性SVM

## 怎么用SVM解决多分类问题

1. 一对多
2. 一对一



## 总结

SVM分类器的概念主要有三个：

1. 完全线性可分情况下的线性分类器，也就是线性可分的情况，是最原始的SVM，它最核心的思想建设找到最大的分类间隔
2. 大部分线性可分情况下的线性分类器，引入了软间隔的概念。软间隔，就是允许一定量的样本分类错误
3. 线性不可分的情况下的非线性分类器，引入了核函数。它让原有的样本空间通过核函数投射到了一个高维的空间中，从而变得线性可分。

SVM的重要知识点

1. 什么是有监督学习，有监督学习就是告诉SVM这个是红的，那个是蓝的，让SVM自动划分出红蓝
2. 无监督学习，无监督学习就是让SVM自己学会认识红色和篮色，并且再对其进行划分
3. 硬间隔，就是在完美数据的完美情况下，做完美的分类
4. 软间隔，就是这些数据总是存在杂质，情况总是那么复杂，分类总是会有一点点小失误
5. 核函数，就是高纬度打低纬度